# deep learning  Chapter 11
## Practical Methodology

---
## disclaimer
- 本文を大胆に要約して整理した
    - 議論のたたき台にしてほしい
    - みんな読んでるよね！！！
- 大事なところが足りないと思ったらコメントしてほしい

---
## Lead
- Deep Learning でいかに問題を解決するか
    - 大半は機械学習一般に共通する話
- 以下の手順を推奨
    1. 指標とその目標値の決定(11.1)
    1. 評価を含む反復実行環境の構築(11.2)
    1. 十分な性能になるまで以下を繰り返す
        1. 性能ボトルネックの見極め(5.4.4, 11.3)
        1. 上記に基づく修正(11.3-11.5)

---
## 11.1 Performance Metrics
- ゴールに向かうよう指標とその目標値を設定
- 性能指標としてよく使われるもの
    - 正解率
    - precision, recall, F-score
- 問題に応じてその他の性能に関する指標も併用

---
## 11.2 Default Baseline Models
- まず全工程をシステム化
    - モデルは簡単or既知のものでよい => ベースラインモデル
- ベースラインモデルの例
    - 単純な確率モデル
    - 適切なディープラーニングモデル
    - 既知の研究結果での使用モデル

---
## 11.3 Determining Whether to Gather More Data
- データの追加収集が基本的に有効な戦略
- 訓練/テストデータでの性能からデータ数以外のボトルネックを把握
    - 実装に問題ないか(学習が正常に進むか)
    - モデルのパラメータ数は適切か
    - データの品質は十分か
- ダメなら追加データ収集 or アルゴリズム改善
---
## 11.4 Selecting Hyperparameters
- 最も重要なハイパーパラメータは学習率
- 手動でのパラメータ探索
    - パラメータ理解と勘と経験
- 自動でのパラメータ探索
    - グリッドサーチ
    - ランダムサーチ
    - ハイパーパラメータのモデル化に基づく探索

---
## 11.5 Debugging Strategies
- 性能の悪さの原因特定は困難
    - アルゴリズムの正しい振る舞い不明
    - 一部に不具合があってもそれを加味して学習が進むため結果には反映されにくい
- デバッグ戦略はこれらを回避するように設計
- つまり
    - 結果の予測できる簡単なケースでテスト
    - 実装の一部を単独で実行してテスト

+++
- 重要なデバッグ戦略の例示
    - モデル出力の可視化
    - 最悪な間違いの可視化
    - 訓練誤差・テスト誤差に基づく使用ソフトの妥当性確認
    - 小さなデータセットでの検証
    - 逆伝播の微分と数値微分の比較
